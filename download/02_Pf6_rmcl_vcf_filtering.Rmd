---
title: "Creating Pf6k filtered SNPs for RMCL"
author: "OJ Watson"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: vignette
    toc: true
    fig_caption: yes
editor_options: 
  chunk_output_type: console
---

```{r imports, echo=F, warning=F, message=F, results='hide'}
library(rslurm)
library(vcfR)
# renv::install("OJWatson/vcfRmanip")
library(vcfRmanip)
```

```{r define directories, echo = FALSE}
# Directory which contains the sub directories
home_dir <- "/gpfs/data/jbailey5/apascha1/"

# Directory where we will do our filtering and subsetting etc
filter_dir <- paste0(home_dir, "pf_release6_COI_filtering")

# Directory where we will download the Pf 6 samples to
sample_dir <- paste0(home_dir, "pf_release6")

# Directory for slurm outputs
slurm_dir <- paste0(home_dir, "slurm_outs")
```

## LD Filtering

In order to run THE REAL McCOIL, we must filter to sites that are not in linkage
disequilibrium.

```{r read files and autocorrelation}
# Find the final intersecting VCF
l <- list.files(filter_dir, full.names = TRUE)
l <- grep("final_coi.vcf", l, value = TRUE)
O <- gsub("_01_v3", "", l[1])

# Read in the final VCF
vcfRobj <- vcfR::read.vcfR(O)

# Calculate autocorrelation
gen <- vcfRmanip::genautocorr(vcfR = vcfRobj)
gen_rds <- paste0(home_dir, "snp_selections/gen.rds")
saveRDS(gen, gen_rds)

# Read rds file paths
gen_rds <- paste0(home_dir, "snp_selections/gen.rds")
vcf_rds <- paste0(home_dir, "snp_selections/vcf_final.rds")
```

```{r ld filtering}
# Define LD filter function
ld_filter <- function(vcfRobj_rds, genauto_rds, threshR2 = 0.8, random = TRUE) {
  vcfRobj <- readRDS(vcfRobj_rds)
  gen <- readRDS(genauto_rds)
  vcfRmanip::vcfR2LDfiltered(
    vcfR = vcfRobj, 
    genautocorrresult = gen,
    threshR2 = threshR2, 
    random = random
  )
}

# Create parameter data frame
pars <- data.frame(
  "vcfRobj_rds" = vcf_rds,
  "genauto_rds" = gen_rds,
  "threshR2" = rep(0.8, 10),
  "random" = TRUE,
  stringsAsFactors = FALSE
)
```

```{r slurm ld filtering}
# Use slurm
setwd(slurm_dir)
sopt <- list(time = "4:00:00", mem = "32Gb")

# Submit job
sjob <- rslurm::slurm_apply(ld_filter,
  pars,
  jobname = "ld_filter",
  nodes = 10,
  global_objects = "ld_filter",
  cpus_per_node = 1,
  slurm_options = sopt,
  submit = TRUE
)
rslurm::get_job_status(sjob)
res <- rslurm::get_slurm_out(sjob)
```

## Running RMCL

Now that we have suitable datasets we need to split them up into their regions
and then create our heterozygous calls for putting into RMCL

```{r}
# function to load vcf and subset to samples in given region, create gt and then RMCL
submit_rmcl <- function(rep, vcf_rds, region, meta_df, path) {

  # read in the vcf
  vcfRobj <- readRDS(vcf_rds)
  if (is.list(vcfRobj)) {
    vcfRobj <- vcfRobj[[1]]
  }

  vcf_num <- gsub(".*(\\d)\\.RDS", "\\1", basename(vcf_rds))

  # subset to samples for this region
  vcfRobj <- vcfRmanip::select_samples(
    vcfRobj, 
    meta_df$Sample[meta_df$cluster == region]
  )

  # create genotype matrix for RMCL (-1, 0, 0.5, 1)
  gtmat <- vcfRmanip::gtmat012(vcfRobj) / 2
  gtmat[is.na(gtmat)] <- -1
  gtmat <- t(gtmat)
  colnames(gtmat) <- rownames(vcfRobj@fix)

  # create output file name
  output <- paste0("cat_region_", region, "_vcf_", vcf_num, "_rep_", rep, ".txt")

  # quick log
  message("Running RMCL")

  # Run RMCL categorical
  out <- McCOILR::McCOIL_categorical(
    data = gtmat,
    maxCOI = 25,
    totalrun = 100000,
    burnin = 1000,
    M0 = 5,
    threshold_ind = round(ncol(gtmat) * 0.25),
    threshold_site = round(nrow(gtmat) * 0.20),
    thin = 0.01,
    err_method = 3,
    path = path,
    output = output
  )

  # remove the trace for file size reasons
  file.path(path, output)
  return(out)
}


# recreate our data frame for the regional clustering

## get the Pf6k sample meta
tf <- tempfile()
download.file("ftp://ngs.sanger.ac.uk/production/malaria/pfcommunityproject/Pf6/Pf_6_samples.txt", tf)
meta <- data.table::fread(tf)

## assign to clusters
df <- meta[meta$`Exclusion reason` == "Analysis_set", c("Lat", "Long", "Sample")]
ks <- cluster::pam(df[, 1:2], k = 24)
df$cluster <- as.factor(ks$clustering)

# create our source vcf paths
vcfs <- grep("results_",
  list.files(paste0(slurm_dir, "rslurm_ld_filter"), full.names = TRUE),
  value = TRUE
)

# build our parameter object list
obj_grid <- expand.grid(rep = 1:5, vcfs = vcfs, regions = unique(df$cluster), stringsAsFactors = FALSE)
obj_list <- vector("list", nrow(obj_grid))
for (i in seq_along(obj_list)) {
  obj_list[[i]]$rep <- obj_grid$rep[i]
  obj_list[[i]]$vcf_rds <- obj_grid$vcfs[i]
  obj_list[[i]]$region <- obj_grid$regions[i]
  obj_list[[i]]$meta_df <- df
  obj_list[[i]]$path <- file.path(here::here(), "analysis/data/derived/McCOIL_work")
}


# submit filter
setwd(slurm_dir)
sopt <- list(time = "24:00:00", mem = "16Gb")

# submit jobs
sjob <- rslurm::slurm_apply(
  f = function(i) {
    submit_rmcl(
      rep = obj_list[[i]]$rep,
      vcf_rds = obj_list[[i]]$vcf_rds,
      region = obj_list[[i]]$region,
      meta_df = obj_list[[i]]$meta_df,
      path = obj_list[[i]]$path
    )
  },
  params = data.frame(i = seq_along(obj_list)),
  global_objects = c("submit_rmcl", "obj_list"),
  jobname = "RMCL",
  nodes = length(obj_list),
  cpus_per_node = 1,
  slurm_options = sopt,
  submit = FALSE
)
rslurm::get_job_status(sjob)
res <- rslurm::get_slurm_out(sjob)
```
