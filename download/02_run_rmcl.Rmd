---
title: "Run THE REAL McCOIL"
author: "OJ Watson, Aris Paschalidis"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: vignette
    toc: true
    fig_caption: yes
editor_options: 
  chunk_output_type: console
---

```{r imports, echo=F, warning=F, message=F, results='hide'}
library(rslurm)
library(vcfR)
# renv::install("OJWatson/vcfRmanip")
library(vcfRmanip)
```

```{r define directories, echo = FALSE}
# Directory which contains the sub directories
home_dir <- "/gpfs/data/jbailey5/apascha1/"

# Directory where we will do our filtering and subsetting etc
filter_dir <- paste0(home_dir, "pf_release6_COI_filtering")

# Directory where we will download the Pf 6 samples to
sample_dir <- paste0(home_dir, "pf_release6")

# Directory for slurm outputs
slurm_dir <- paste0(home_dir, "slurm_outs")
```

## LD Filter

In order to run THE REAL McCOIL, we must filter to sites that are not in linkage
disequilibrium.

```{r read files and autocorrelation}
# Find the final intersecting VCF
l <- list.files(filter_dir, full.names = TRUE)
l <- grep("final_coi.vcf", l, value = TRUE)
O <- gsub("_01_v3", "", l[1])

# Read in the final VCF
vcfRobj <- vcfR::read.vcfR(O)

# Calculate autocorrelation
gen <- vcfRmanip::genautocorr(vcfR = vcfRobj)
gen_rds <- paste0(home_dir, "snp_selections/gen.rds")
saveRDS(gen, gen_rds)

# Read rds file paths
gen_rds <- paste0(home_dir, "snp_selections/gen.rds")
vcf_rds <- paste0(home_dir, "snp_selections/vcf_final.rds")
```

```{r ld filtering}
# Define LD filter function
ld_filter <- function(vcfRobj_rds, genauto_rds, threshR2 = 0.8, random = TRUE) {
  vcfRobj <- readRDS(vcfRobj_rds)
  gen <- readRDS(genauto_rds)
  vcfRmanip::vcfR2LDfiltered(
    vcfR = vcfRobj, 
    genautocorrresult = gen,
    threshR2 = threshR2, 
    random = random
  )
}

# Create parameter data frame
pars <- data.frame(
  "vcfRobj_rds" = vcf_rds,
  "genauto_rds" = gen_rds,
  "threshR2" = rep(0.8, 5),
  "random" = TRUE,
  stringsAsFactors = FALSE
)
```

```{r slurm ld filtering}
# Use slurm
setwd(slurm_dir)
sopt <- list(time = "4:00:00", mem = "32Gb")

# Submit job
sjob <- rslurm::slurm_apply(ld_filter,
  pars,
  jobname = "ld_filter",
  nodes = nrow(pars),
  global_objects = "ld_filter",
  cpus_per_node = 1,
  slurm_options = sopt,
  submit = TRUE
)
rslurm::get_job_status(sjob)
res <- rslurm::get_slurm_out(sjob)
```

## Run RMCL

Now that we have suitable datasets we need to split them up into their regions
and then create our heterozygous calls for putting into RMCL

```{r run rmcl function}
# Define function to load vcf and subset to samples in given region, create gt
# matrix, and then run RMCL
submit_rmcl <- function(rep, vcf_rds, region, meta_df, path) {
  # Read in the vcf
  vcfRobj <- readRDS(vcf_rds)
  if (is.list(vcfRobj)) {
    vcfRobj <- vcfRobj[[1]]
  }

  # Determine vcf number
  vcf_num <- gsub(".*(\\d)\\.RDS", "\\1", basename(vcf_rds))

  # subset to samples for this region
  vcfRobj <- vcfRmanip::select_samples(
    vcfRobj, 
    meta_df$Sample[meta_df$cluster == region]
  )

  # Create genotype matrix for RMCL (-1, 0, 0.5, 1)
  gtmat <- vcfRmanip::gtmat012(vcfRobj) / 2
  gtmat[is.na(gtmat)] <- -1
  gtmat <- t(gtmat)
  colnames(gtmat) <- rownames(vcfRobj@fix)

  # Create output file name
  output <- paste0("cat_region_", region, "_vcf_", vcf_num, "_rep_", rep, ".txt")

  # Quick log
  message("Running RMCL")

  # Run RMCL categorical
  out <- McCOILR::McCOIL_categorical(
    data = gtmat,
    maxCOI = 25,
    totalrun = 5000,
    burnin = 1000,
    M0 = 5,
    threshold_ind = round(ncol(gtmat) * 0.25),
    threshold_site = round(nrow(gtmat) * 0.20),
    thin = 0.01,
    err_method = 3,
    path = path,
    output = output
  )

  # Remove the trace for file size reasons
  file.path(path, output)
  return(out)
}
```

```{r metadata and vcfs}
# First recreate our data frame for the regional clustering
# Get the Pf6k sample meta
tf <- tempfile()
download.file("ftp://ngs.sanger.ac.uk/production/malaria/pfcommunityproject/Pf6/Pf_6_samples.txt", tf)
meta <- data.table::fread(tf)

# Assign to clusters
df <- meta[meta$`Exclusion reason` == "Analysis_set", c("Lat", "Long", "Sample")]
ks <- cluster::pam(df[, 1:2], k = 24)
df$cluster <- as.factor(ks$clustering)

# Find our LD filtered VCFs
vcfs <- grep("results_",
  list.files(paste0(slurm_dir, "/_rslurm_ld_filter"), full.names = TRUE),
  value = TRUE
)
```

Next, we create our object list.

```{r rmcl object list}
# Build object list
obj_grid <- expand.grid(
  rep = 1:5, 
  vcfs = vcfs, 
  regions = unique(df$cluster), 
  stringsAsFactors = FALSE
)
obj_list <- vector("list", nrow(obj_grid))
for (i in seq_along(obj_list)) {
  obj_list[[i]]$rep <- obj_grid$rep[i]
  obj_list[[i]]$vcf_rds <- obj_grid$vcfs[i]
  obj_list[[i]]$region <- obj_grid$regions[i]
  obj_list[[i]]$meta_df <- df
  obj_list[[i]]$path <- paste0(home_dir, "rmcl")
}
```

Note that our object list contains over 1,000 elements, which may be too large
of a job to submit to a cluster. We may break the job up into multiple smaller
jobs by considering each of the 10 VCFs one at a time. For instance, we can
create a new object list as follows.

```{r rmcl object list, eval = FALSE}
# Build object list for the first VCF
obj_grid <- expand.grid(
  rep = 1:5, 
  vcfs = vcfs[1], 
  regions = unique(df$cluster), 
  stringsAsFactors = FALSE
)
obj_list <- vector("list", nrow(obj_grid))
for (i in seq_along(obj_list)) {
  obj_list[[i]]$rep <- obj_grid$rep[i]
  obj_list[[i]]$vcf_rds <- obj_grid$vcfs[i]
  obj_list[[i]]$region <- obj_grid$regions[i]
  obj_list[[i]]$meta_df <- df
  obj_list[[i]]$path <- paste0(home_dir, "rmcl")
}
```

```{r slurm run rmcl}
# Use slurm
setwd(slurm_dir)
sopt <- list(time = "12:00:00", mem = "20Gb")

# Submit jobs
sjob <- rslurm::slurm_apply(
  f = function(i) {
    submit_rmcl(
      rep = obj_list[[i]]$rep,
      vcf_rds = obj_list[[i]]$vcf_rds,
      region = obj_list[[i]]$region,
      meta_df = obj_list[[i]]$meta_df,
      path = obj_list[[i]]$path
    )
  },
  params = data.frame(i = seq_along(obj_list)),
  global_objects = c("submit_rmcl", "obj_list"),
  jobname = "RMCL",
  nodes = length(obj_list),
  cpus_per_node = 1,
  slurm_options = sopt,
  submit = TRUE
)
rslurm::get_job_status(sjob)
res <- rslurm::get_slurm_out(sjob)
```

## Save Estimated COI

```{r estimated coi}
l <- list.files(paste0(home_dir, "rmcl"), full.names = TRUE)
summary_files <- grep("summary", l, value = TRUE)

summary_tbls <- lapply(summary_files, data.table::fread)
names(summary_tbls) <- basename(summary_files)

coi <- data.table::rbindlist(
  lapply(
    summary_tbls[!unlist(lapply(summary_tbls, function(x) {
      nrow(x) == 0
    }))],
    function(x) {
      df <- data.frame(
        "COI" = x[x$CorP == "C"]$median,
        "COI_025" = x[x$CorP == "C"]$quantile0.025,
        "COI_975" = x[x$CorP == "C"]$quantile0.975,
        "region" = unique(stringr::str_extract(x$file, "\\d{1,2}")),
        "file" = x[x$CorP == "C"]$file,
        "name" = x$name[x$CorP == "C"]
      )
    }
  )
)
saveRDS(coi, paste0(home_dir, "rmcl/rmcl_coi.rds"))
```
